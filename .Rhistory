xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos <- unlist(pos)
storenames <- character(length(pos))
pos[length(pos)+1] <- length(pos)+10
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
pos
pos[length(pos)+1] <- pos[length(pos)]+10
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
length(string2)
string2
pos = gregexpr('[pP]apilio', string2)
pos <- unlist(pos)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],nchar(string2))
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
nchar(string2)
pos
pos2 = gregexpr(', [0-9]', string2)
pos2
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos2[length[pos2]]+4)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+4)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
xData <- getURL(url) # This allows us to use https
# parsing the html content
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
# finally getting the genus name by regular expression search and replace
genusName <- sub(".*?<i>(.*?)</i>.*", "\\1", x)
genusName
library(XML)
library(RCurl)
Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
xData <- getURL(url) # This allows us to use https
# parsing the html content
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
# finally getting the genus name by regular expression search and replace
genusName <- sub(".*?<i>(.*?)</i>.*", "\\1", x)
genusName
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
# loop to get through the string and devide it into various required substrings
for(i in 1:length(pos))
{
if(i == length(pos))
{
# precision at last part of the string so pos2 has been created
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
write.csv(storenames,"easypart2specieslist.csv")
require(RCurl)
require(XML)
require(rvest)
# ---- Medium: Part 1 ----
# ---- Read HTML and get all the species names -----
html_data<- read_html("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
# ---- Cleaning ----
raw_species <- gsub("=", "", raw_species)
species_names <- gsub(";.*", "", raw_species)
# ----- Output: Total 21 Species Names present in html -----
species_names
# ---- Medium: Part 2 ----
# ---- Convert part 1 into function -----
speciesNames <- function(url){
html_data <- read_html(url)
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
#Cleaning
raw_species <- gsub("=", "", raw_species)
species_names <- gsub(";.*", "", raw_species)
#Output
return(species_names)
}
speciesNames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
raw_species
html_data
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
xData <- getURL(url) # This allows us to use https
# parsing the html content
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
x
html_data<- read_html("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
Sys.setenv(http_proxy="http://10.3.100.207:8080")
html_data<- read_html("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
html_data
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
raw_species
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
html_data<- read_html("url")
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
html_data<- read_html(url)
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
raw_species
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
species
species[2]
speciesNames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
gsub(";.*",species)
gsub(";.*","",species)
gsub("=|;.*","",species)
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
speciesListfinal
write.csv(speciesListfinal,"mediumpart1speciesList.csv")
write.csv(speciesListfinal,"mediumpart1speciesList.csv")
speciesnames <- function(url){
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
#url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
write.csv(speciesListfinal,"mediumpart1speciesList.csv")
}
speciesnames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
speciesnames <- function(url){
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
#url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
speciesListfinal
}
speciesnames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
url <- "https://github.com/vijaybarve/Parser-GSOC2017-idea/blob/master/taxo_out01.csv"
download.file(url,destfile="datagit.csv")
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
# loop to get through the string and devide it into various required substrings
for(i in 1:length(pos))
{
if(i == length(pos))
{
# precision at last part of the string so pos2 has been created
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
# loop to get through the string and devide it into various required substrings
for(i in 1:length(pos))
{
if(i == length(pos))
{
# precision at last part of the string so pos2 has been created
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
# loop to get through the string and devide it into various required substrings
for(i in 1:length(pos))
{
if(i == length(pos))
{
# precision at last part of the string so pos2 has been created
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
list()
View(adData)
rm(list=ls())
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
# loop to get through the string and devide it into various required substrings
for(i in 1:length(pos))
{
if(i == length(pos))
{
# precision at last part of the string so pos2 has been created
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
# loop to get through the string and devide it into various required substrings
for(i in 1:length(pos))
{
if(i == length(pos))
{
# precision at last part of the string so pos2 has been created
storenames[i] <- substr(string2,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(string2,pos[i],pos[i+1]-1)
}
storenames
require(RCurl)
require(XML)
require(rvest)
Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
# reading url
readhtml <- read_html(url)
# using rvest library to get the node text
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
speciesListfinal
rm(list=ls())
library(stringr)
data <- read.table("taxo01.txt",sep = "\t")
#distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
#DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
setwd("~/gsoc2017tests")
library(stringr)
data <- read.table("taxo01.txt",sep = "\t")
#distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
#DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
NAMES
stringnew <- paste(data$V1,collapse = " ")
y <- str_locate_all(pattern ='Distribution.*?[0-9.]',stringnew)
y <- data.frame(y)
Y
y
distributionlist <- character(length(y$start))
for(i in 1:length(y$start))
distributionlist[i] <- substr(stringnew,y$start[i],y$end[i]-2)
distributionlist
distributionlist <- gsub("^Distribution: ","",distributionlist)
distributionlist
finaldata <- data.frame("NAME"= NAMES , "DISTRIBUTION"= distributionlist)
finaldata
write.csv(finaldata,"hardpart1formatted_data.csv")
finaldata
finaldata$DISTRIBUTION
finaldata$DISTRIBUTION[5]
write.csv(finaldata,"hardpart1formatted_data.csv")
tocsv <- function(textfile){
library(stringr)
data <- read.table(textfile,sep = "\t")
#distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
#DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
#col1 <- data$V1[1]
#finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
stringnew <- paste(data$V1,collapse = " ")
#x <- str_locate_all(pattern ='[0-9]. ',stringnew)
y <- str_locate_all(pattern ='Distribution.*?[0-9.]',stringnew)
y <- data.frame(y)
distributionlist <- character(length(y$start))
for(i in 1:length(y$start))
distributionlist[i] <- substr(stringnew,y$start[i],y$end[i]-2)
distributionlist <- gsub("^Distribution: ","",distributionlist)
finaldata2 <- data.frame("NAME"= NAMES , "DISTRIBUTION"= distributionlist)
finaldata2
}
tocsv("taxo01.txt")
tocsv <- function(textfile){
library(stringr)
data <- read.table(textfile,sep = "\t")
#distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
#DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
#col1 <- data$V1[1]
#finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
stringnew <- paste(data$V1,collapse = " ")
#x <- str_locate_all(pattern ='[0-9]. ',stringnew)
y <- str_locate_all(pattern ='Distribution.*?[0-9.]',stringnew)
y <- data.frame(y)
distributionlist <- character(length(y$start))
for(i in 1:length(y$start))
distributionlist[i] <- substr(stringnew,y$start[i],y$end[i]-2)
distributionlist <- gsub("^Distribution: ","",distributionlist)
finaldata2 <- data.frame("NAME"= NAMES , "DISTRIBUTION"= distributionlist)
write.csv(finaldata2,"abc.csv")
}
tocsv("taxo01.txt")
tocsv <- function(textfile){
library(stringr)
data <- read.table(textfile,sep = "\t")
#distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
#DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
#col1 <- data$V1[1]
#finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
stringnew <- paste(data$V1,collapse = " ")
#x <- str_locate_all(pattern ='[0-9]. ',stringnew)
y <- str_locate_all(pattern ='Distribution.*?[0-9.]',stringnew)
y <- data.frame(y)
distributionlist <- character(length(y$start))
for(i in 1:length(y$start))
distributionlist[i] <- substr(stringnew,y$start[i],y$end[i]-2)
distributionlist <- gsub("^Distribution: ","",distributionlist)
finaldata2 <- data.frame("NAME"= NAMES , "DISTRIBUTION"= distributionlist)
#write.csv(finaldata2,"abc.csv")
finaldata2
}
tocsv("taxo01.txt")
