x <- as(doc, "character")
rawData <- sub(".*?<i>(.*?)</a>", "\\1", x)
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url)
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url)
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
rawData <- sub(".*?<i>(.*?)</a>", "\\1", x)
rawData
rawSpecies <- grep("species/Papilio",x)
rawSpecies
rawData <- gsub(".*?<i>(.*?)</a>", "\\1", x)
rawData
listSpecies <- gsub( "</i>", "", rawData)
listSpecies
y <- grep([0-9],listSpecies)
y <- grep(", [0-9]",listSpecies)
y
pos = gregexpr(', [0-9]', listSpecies)
pos
listSpecies[pos[1]]
pos[1]
substr(listSpecies,pos)
str(pos)
as(pos,"numeric")
pos[[1]]
as.numeric(pos)
unlist(pos)
pos <- as.numeric(pos)
pos <- unlist(pos)
pos[1]
pos[2]
listSpecies[34]
listSpecies[70]
listSpecies
substr(listSpecies,34,70)
substr(listSpecies,34+5,70)
substr(listSpecies,34+6,70)
substr(listSpecies,34+6,70+6)
substr(listSpecies,34+6,70+4)
substr(listSpecies,34+6,70+5)
for(i in length(pos)){
string[i] = substr( listSpecies,pos[i]+6,pos[i+1]+4 )
}
pos <- unlist(pos)
string = character(length(pos))
for(i in length(pos)){
string[i] = substr( listSpecies,pos[i]+6,pos[i+1]+4 )
}
string
substr(listSpecies,34+6,70-1)
for(i in length(pos)){
substr( listSpecies,pos[i]+6,pos[i+1]+4 )
}
for(i in length(pos)){
print(substr( listSpecies,pos[i]+6,pos[i+1]+4 ))
}
pos
pos = gregexpr('[pP]apilio', listSpecies)
pos
pos <- unlist(pos)
pos
substr(listSpecies,pos[1],pos[2])
substr(listSpecies,pos[1],pos[2]-1)
storenames <- character(length(pos))
storenames
storenames[10]
storenames[10] <- substr(listSpecies,pos[1],pos[2]-1)
storenames
for(i in length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
for(i in 1:length(pos))
{
storenames <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
for(i in 1:length(pos))
{
print( pos[i]) print ("  ") print(pos[i+1])
}
for(i in 1:length(pos))
print( pos[i]) print ("  ") print(pos[i+1])
for(i in 1:length(pos))
print( pos[i]) print ("  ") print(pos[i+1]))
for(i in 1:length(pos))
{
print(pos[i])
print ("  ")
print(pos[i+1]))
}
for(i in 1:length(pos))
{
print(pos[i])
print("  ")
print(pos[i+1]))
}
for(i in 1:length(pos))
{
print(pos[i])
print("  ")
print(pos[i+1])
}
for(i in 1:length(pos))
{
print(pos[i])
print(pos[i+1])
}
for(i in 1:length(pos))
{
print(substr(listSpecies,pos[i],pos[i+1]-1))
}
storenames <- character(length(pos))
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
pos[length(pos)+1] <- length(pos)
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos <- unlist(pos)
storenames <- character(length(pos))
pos[length(pos)+1] <- length(pos)+10
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
library(XML)
library(RCurl)
Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos <- unlist(pos)
storenames <- character(length(pos))
pos[length(pos)+1] <- length(pos)+10
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos <- unlist(pos)
storenames <- character(length(pos))
pos[length(pos)+1] <- length(pos)+10
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
pos
pos[length(pos)+1] <- pos[length(pos)]+10
for(i in 1:length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
length(string2)
string2
pos = gregexpr('[pP]apilio', string2)
pos <- unlist(pos)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],nchar(string2))
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
nchar(string2)
pos
pos2 = gregexpr(', [0-9]', string2)
pos2
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos2[length[pos2]]+4)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+4)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
for(i in 1:length(pos))
{
if(i == length(pos))
{
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
storenames
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
xData <- getURL(url) # This allows us to use https
# parsing the html content
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
# finally getting the genus name by regular expression search and replace
genusName <- sub(".*?<i>(.*?)</i>.*", "\\1", x)
genusName
library(XML)
library(RCurl)
Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
xData <- getURL(url) # This allows us to use https
# parsing the html content
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
# finally getting the genus name by regular expression search and replace
genusName <- sub(".*?<i>(.*?)</i>.*", "\\1", x)
genusName
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="http://10.3.100.207:8080")
url <- "https://www.abdb-africa.org/genus/Papilio"
xData <- getURL(url) # This allows us to use https
# parsing the URL
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
string1 <- gsub(".*?<i>(.*?)</a>", "\\1", x)
# data obtaines is still in the form of single string
string2 <- gsub( "</i>", "", string1)
pos = gregexpr('[pP]apilio', string2)
pos2 = gregexpr(', [0-9]', string2)
pos <- unlist(pos)
pos2 <- unlist(pos2)
storenames <- character(length(pos))
# loop to get through the string and devide it into various required substrings
for(i in 1:length(pos))
{
if(i == length(pos))
{
# precision at last part of the string so pos2 has been created
storenames[i] <- substr(listSpecies,pos[i],pos2[length(pos2)]+5)
}
else
storenames[i] <- substr(listSpecies,pos[i],pos[i+1]-1)
}
write.csv(storenames,"easypart2specieslist.csv")
require(RCurl)
require(XML)
require(rvest)
# ---- Medium: Part 1 ----
# ---- Read HTML and get all the species names -----
html_data<- read_html("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
# ---- Cleaning ----
raw_species <- gsub("=", "", raw_species)
species_names <- gsub(";.*", "", raw_species)
# ----- Output: Total 21 Species Names present in html -----
species_names
# ---- Medium: Part 2 ----
# ---- Convert part 1 into function -----
speciesNames <- function(url){
html_data <- read_html(url)
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
#Cleaning
raw_species <- gsub("=", "", raw_species)
species_names <- gsub(";.*", "", raw_species)
#Output
return(species_names)
}
speciesNames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
raw_species
html_data
library(XML)
library(RCurl)
#Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
xData <- getURL(url) # This allows us to use https
# parsing the html content
doc <- htmlTreeParse(xData,useInternalNodes = TRUE)
x <- as(doc, "character")
x
html_data<- read_html("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
Sys.setenv(http_proxy="http://10.3.100.207:8080")
html_data<- read_html("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
html_data
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
raw_species
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
html_data<- read_html("url")
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
html_data<- read_html(url)
raw_species <- html_data %>% html_nodes(".NAMES .SN li") %>% html_text()
raw_species
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
species
species[2]
speciesNames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
gsub(";.*",species)
gsub(";.*","",species)
gsub("=|;.*","",species)
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
speciesListfinal
write.csv(speciesListfinal,"mediumpart1speciesList.csv")
write.csv(speciesListfinal,"mediumpart1speciesList.csv")
speciesnames <- function(url){
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
#url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
write.csv(speciesListfinal,"mediumpart1speciesList.csv")
}
speciesnames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
speciesnames <- function(url){
require(RCurl)
require(XML)
require(rvest)
#Sys.setenv(http_proxy="")
#url <- "http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/"
readhtml <- read_html(url)
species <- readhtml %>% html_nodes(".NAMES .SN li") %>% html_text()
speciesListfinal <- gsub("=|;.*","",species)
speciesListfinal
}
speciesnames("http://ftp.funet.fi/pub/sci/bio/life/insecta/lepidoptera/ditrysia/papilionoidea/papilionidae/papilioninae/lamproptera/")
url <- "https://github.com/vijaybarve/Parser-GSOC2017-idea/blob/master/taxo_out01.csv"
download.file(url,destfile="datagit.csv")
read.table("taxo01.txt")
setwd("~/gsoc2017tests")
setwd("~/gsoc2017tests")
read.table("taxo01.txt")
read.table("taxo01.txt",sep = \t)
read.table("taxo01.txt",sep = "\t")
data <- read.table("taxo01.txt",sep = "\t")
str(data)
summary(data)
data$V1
dis<- grep("^Distribution", data$V1)
dis
data[dis]
data[dis,]
grep("^[0-9]",data)
grep("^[0-9]",data$V1)
namesindex <- grep("^[0-9]",data$V1)
data[namesindex,]
data <- read.table("taxo01.txt",sep = "\t")
distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
col1 <- data$V1[1]
data.frame(col1,NAMES,DISTRIBUTION)
NAMES <- sub("^[0-9][0-9]. ","",NAMES)
NAMES
data <- read.table("taxo01.txt",sep = "\t")
distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9][0-9]. ","",NAMES)
col1 <- data$V1[1]
finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
write.csv(finaldata,"formatted_data.csv")
NAMES <- data[namesindex,]
NAMES
NAMES <- sub("^[0-9].|^[0-9][0-9] ","",NAMES)
NAMES
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
NAMES
data <- read.table("taxo01.txt",sep = "\t")
distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
col1 <- data$V1[1]
finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
write.csv(finaldata,"formatted_data.csv")
data <- read.table("taxo01.txt",sep = "\t")
distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
col1 <- data$V1[1]
finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
write.csv(finaldata,"formatted_data.csv")
data <- read.table("taxo01.txt",sep = "\t")
distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
col1 <- data$V1[1]
finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
write.csv(finaldata,"HARDPART1formatted_data.csv")
tocsv <- function(textfile){
data <- read.table(textfile,sep = "\t")
distribution <- grep("^Distribution", data$V1)
namesindex <- grep("^[0-9]",data$V1)
DISTRIBUTION <- data[distribution,]
NAMES <- data[namesindex,]
NAMES <- sub("^[0-9].|^[0-9][0-9]. ","",NAMES)
col1 <- data$V1[1]
finaldata <- data.frame(col1,NAMES,DISTRIBUTION)
finaldata
}
tocsv("taxo01.txt")
